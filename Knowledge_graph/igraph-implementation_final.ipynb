{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:00.638228100Z",
     "start_time": "2025-04-09T12:55:39.521016600Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pydantic import BaseModel,Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from ER_extraction import entities_out\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "load_dotenv()\n",
    "# Groq api key define\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "# OPENAI api key define\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "# model = ChatOpenAI(model=\"gpt-4o\",base_url=os.getenv(\"base_url\"))\n",
    "\n",
    "# Deepseek api key define\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "model = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# Web search api define\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entities': [{'entity_name': 'milk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' butter', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' ghee', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' yoghurt', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' buttermilk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cheese', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cattle', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' sheep', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' goat', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' yak', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' buffalo', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' mozzarella', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Italy', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' gulab jamun', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' India', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Roquefort', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' France', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cow', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Camembert', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Cheddar', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'cattle', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' water buffalo', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' goat', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' sheep', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' camel', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' donkey', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' horse', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' reindeer', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' yak', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Montbéliarde', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'Montbéliarde', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Holsteins', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'cows', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' buffalo', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' goats', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' sheep', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' France', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' New York City', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Statue of Liberty', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Liberty Island', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Hudson River', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Paris', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Eiffel Tower', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Louvre Museum', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Mona Lisa', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Silicon Valley', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Apple', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Google', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Apple Park', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Cupertino', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'cattle', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' goats', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' sheep', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Streptococcus lactis', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' calf', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'milk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' curds', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cheese', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' countries', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' bacteria', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' whey', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' lactose', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Emmental', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Cheddar', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'whole milk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' traditional cheeses', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' commercial cheeses', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'goat cheese', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' goat milk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' domestic goats', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': \" cow's milk\", 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' goats', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cows', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' sheep', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': \"goat's milk\", 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': \" cow's milk\", 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' caproic', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' caprylic', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': \" goat's milk cheese\", 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Latin', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' capra', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' lactose', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': \" cow's milk\", 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cheddar cheese', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' curds', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' whey', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' rennet', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' enzyme complex', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' stomachs', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' newborn calves', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' bacterial', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' yeast', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' mould-derived chymosin', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' vegetarian', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' kosher cheeses', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Dairy cattle', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': 'milk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' cheese', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' whey protein', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' casein', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' protein bars', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' beverages', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' concentrated powder', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' soy', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' meat', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' wheat', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' Diafiltered milk', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' lactose', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' water', 'entity_type': '', 'description': '', 'source_id': ''}, {'entity_name': ' low-carb dairy products', 'entity_type': '', 'description': '', 'source_id': ''}], 'relationships': [{'src_id': 'milk', 'tgt_id': 'cheese', 'description': 'is used to make', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'buffalo', 'tgt_id': 'mozzarella', 'description': 'is used to make', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'mozzarella', 'tgt_id': 'Italy', 'description': 'is made in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'sheep', 'tgt_id': 'Roquefort', 'description': 'is used to make', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Roquefort', 'tgt_id': 'France', 'description': 'is made in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'yak', 'tgt_id': 'milk', 'description': 'is used to produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'goat', 'tgt_id': 'milk', 'description': 'is used to produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'cow', 'tgt_id': 'milk', 'description': 'is used to produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'cattle', 'tgt_id': 'milk', 'description': 'is used to produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Camembert', 'tgt_id': 'Cheddar', 'description': 'is made using a process similar to', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Goat', 'tgt_id': 'milk', 'description': 'produces', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Milk', 'tgt_id': 'cheese production', 'description': 'used for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Cheese', 'tgt_id': 'milk of cows, buffalo, goats or sheep', 'description': 'made from', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Cattle', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Water buffalo', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Sheep', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Camel', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Donkey', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Horse', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Reindeer', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Yak', 'tgt_id': 'milk', 'description': 'produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Montbéliarde', 'tgt_id': 'Holsteins', 'description': 'is compared to', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Montbéliarde', 'tgt_id': 'cheesemaking', 'description': 'is suited for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Holsteins', 'tgt_id': 'milk yields than Montbéliarde', 'description': 'have higher', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Cheese', 'tgt_id': 'milk of cows, buffalo, goats, or sheep', 'description': 'is produced from', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Cows', 'tgt_id': 'producing milk and milk products for human consumption', 'description': 'are used for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Apple', 'tgt_id': 'Cupertino, Silicon Valley', 'description': 'has its headquarters in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Statue of Liberty', 'tgt_id': 'New York City, on Liberty Island, near the Hudson River', 'description': 'is located in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Eiffel Tower', 'tgt_id': 'Paris', 'description': 'is located in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Louvre Museum', 'tgt_id': 'Paris and houses the Mona Lisa', 'description': 'is situated in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'cattle', 'tgt_id': 'blue cheese', 'description': 'produces milk for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'goats', 'tgt_id': 'blue cheese', 'description': 'produces milk for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'sheep', 'tgt_id': 'blue cheese', 'description': 'produces milk for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Streptococcus lactis', 'tgt_id': 'acidification process of blue cheese', 'description': 'is used in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'calf', 'tgt_id': 'rennet for blue cheese production', 'description': 'is source of', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Cheese', 'tgt_id': 'milk', 'description': 'is made from', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Milk', 'tgt_id': 'cheese', 'description': 'can be processed to form', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Countries', 'tgt_id': 'milk to be processed without pasteurization', 'description': 'allow', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Bacteria', 'tgt_id': 'milk', 'description': 'are found naturally in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Whey', 'tgt_id': 'cheese production', 'description': 'is a byproduct of', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Lactose intolerant people', 'tgt_id': 'certain types of cheese', 'description': 'can eat', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Emmental', 'tgt_id': 'traditionally made hard cheese', 'description': 'is a type of', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Cheddar', 'tgt_id': 'traditionally made hard cheese', 'description': 'is a type of', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'whole milk', 'tgt_id': 'traditional cheeses', 'description': 'is used to produce', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'traditional cheeses', 'tgt_id': 'commercial cheeses', 'description': 'have reduced lactose content compared to', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'commercial cheeses', 'tgt_id': 'traditional cheeses', 'description': 'are manufactured by processes that do not reduce lactose content like', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Goat cheese', 'tgt_id': 'goat milk', 'description': 'is produced from', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Goat milk', 'tgt_id': 'cultured dairy products', 'description': 'is used to make', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Goats', 'tgt_id': 'cows', 'description': 'are smaller than', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Goats', 'tgt_id': 'cows', 'description': 'are easier to transport and herd than', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Goats', 'tgt_id': 'any time of the year', 'description': 'can breed', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Sheep', 'tgt_id': 'only during fall and winter', 'description': 'have a mating season', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': \"goat's milk\", 'tgt_id': \"cow's milk\", 'description': 'has similar fat content to', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': \"goat's milk\", 'tgt_id': 'medium-chain fatty acids', 'description': 'contains', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'medium-chain fatty acids', 'tgt_id': \"tart flavor of goat's milk cheese\", 'description': 'contribute to', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': \"goat's milk\", 'tgt_id': \"cow's milk\", 'description': 'has lower lactose content than', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'cheddar cheese', 'tgt_id': 'rennet', 'description': 'is manufactured using', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'rennet', 'tgt_id': 'stomachs of newborn calves', 'description': 'is derived from', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'bacterial, yeast or mould-derived chymosin', 'tgt_id': 'vegetarian or kosher cheeses', 'description': 'is used in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Whey protein', 'tgt_id': 'casein', 'description': 'is separated from', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Whey protein', 'tgt_id': 'protein bars, beverages and concentrated powder', 'description': 'is used in', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Diafiltered milk', 'tgt_id': 'ultrafiltration of fluid milk', 'description': 'is a process of', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Diafiltered milk', 'tgt_id': 'more efficiency in cheese making', 'description': 'allows for', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Whey protein', 'tgt_id': 'high quality amino acid profile', 'description': 'contains', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Casein', 'tgt_id': '80% of milk’s protein make up', 'description': 'makes up', 'keywords': '', 'weight': 1.0, 'source_id': ''}, {'src_id': 'Whey protein', 'tgt_id': '20% of milk’s protein composition', 'description': 'makes up', 'keywords': '', 'weight': 1.0, 'source_id': ''}], 'chunks': [{'content': '[\\n  {\\n    \"title\": \"Bovidae\",\\n    \"text\": \"Dairy products such as milk, butter, ghee, yoghurt, buttermilk and cheese are manufactured largely from domestic cattle, though the milk of sheep, goat, yak, and buffalo is also used in some parts of the world and for gourmet products. For example, buffalo milk is used to make mozzarella in Italy and \\\\\"gulab jamun\\\\\" dessert in India, while sheep milk is used to make blue Roquefort cheese in France.\"\\n  },\\n  {\\n    \"title\": \"Cheesemaking\",\\n    \"text\": \"The goal of cheese making is to control the spoiling of milk into cheese. The milk is traditionally from a cow, goat, sheep or buffalo, although, in theory, cheese could be made from the milk of any mammal. Cow\\'s milk is most commonly used worldwide. The cheesemaker\\'s goal is a consistent product with specific characteristics (appearance, aroma, taste, texture). The process used to make a Camembert will be similar to, but not quite the same as, that used to make Cheddar.\"\\n  },\\n  {', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"Goat\",\\n    \"text\": \"Goat milk naturally has small, well-emulsified fat globules, which means the cream remains suspended in the milk, instead of rising to the top, as in raw cow milk; therefore, it does not need to be homogenized. Indeed, if the milk is to be used to make cheese, homogenization is not recommended, as this changes the structure of the milk, affecting the culture\\'s ability to coagulate the milk and the final quality and yield of cheese.\"\\n  },\\n  {\\n    \"title\": \"Cheese (disambiguation)\",\\n    \"text\": \"Cheese is a dairy product usually made from the milk of cows, buffalo, goats or sheep.\"\\n  },\\n  {\\n    \"title\": \"Milk\",\\n    \"text\": \"Aside from cattle, many kinds of livestock provide milk used by humans for dairy products. These animals include water buffalo, goat, sheep, camel, donkey, horse, reindeer and yak. The first four respectively produced about 11%, 2%, 1.4% and 0.2% of all milk worldwide in 2011.\"\\n  },\\n  {\\n    \"title\": \"Montbéliarde\",', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"Montbéliarde\",\\n    \"text\": \"The animals are red pied with white heads and short horns, and of dairy type. Mature cows weigh and stand about tall at the withers, and mature bulls weigh . The milk is particularly well suited to cheesemaking because of a high frequency of kappa casein BB variants, giving higher yields of cheese. Being of less extreme dairy type than modern Holsteins, the cows have lower milk yields, but better longevity and fertility and lower cell counts in the milk, indicating lower mastitis incidence.\"\\n  },\\n  {\\n    \"title\": \"Cheese\",', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"Cheese\",\\n    \"text\": \"Cheese is a dairy product produced in wide ranges of flavors, textures and forms by coagulation of the milk protein casein. It comprises proteins and fat from milk, usually the milk of cows, buffalo, goats, or sheep. During production, the milk is usually acidified and the enzymes of either rennet or bacterial enzymes with similar activity are added to cause the casein to coagulate. The solid curds are then separated from the liquid whey and pressed into finished cheese. Some cheeses have aromatic molds on the rind, the outer layer, or throughout.\"\\n  },\\n  {\\n    \"title\": \"Animal husbandry\",\\n    \"text\": \"Although all mammals produce milk to nourish their young, the cow is predominantly used throughout the world to produce milk and milk products for human consumption. Other animals used to a lesser extent for this purpose include sheep, goats, camels, buffaloes, yaks, reindeer, horses and donkeys.\"\\n  },\\n  {\\n    \"title\": \"Blue cheese\",', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"Blue cheese\",\\n    \"text\": \"First, raw milk (either from cattle, goats or sheep) is mixed and pasteurized at for 15 seconds. Then, acidification occurs: a starter culture, such as \\\\\"Streptococcus lactis,\\\\\" is added in order to change lactose to lactic acid, thus changing the acidity of the milk and turning it from liquid to solid. The next step is coagulation, where rennet, a mixture of rennin and other material found in the stomach lining of a calf is added to solidify the milk further. Following this, thick curds are cut typically with a knife to encourage the release of liquid or whey. The smaller the curds are cut, the thicker and harder the resulting cheese will become.\"\\n  },\\n  {\\n    \"title\": \"Dairy\",', 'source_id': ''}, {'content': '\"text\": \"Cheese is another product made from milk. Whole milk is reacted to form curds that can be compressed, processed and stored to form cheese. In countries where milk is legally allowed to be processed without pasteurization, a wide range of cheeses can be made using the bacteria found naturally in the milk. In most other countries, the range of cheeses is smaller and the use of artificial cheese curing is greater. Whey is also the byproduct of this process. Some people with lactose intolerance are surprisingly able to eat certain types of cheese. This is because some traditionally made hard cheeses, and soft ripened cheeses may create less reaction than the equivalent amount of milk because of the processes involved. Fermentation and higher fat content contribute to lesser amounts of lactose. Traditionally made Emmental or Cheddar might contain 10% of the lactose found in whole milk. In addition, the aging methods of traditional cheeses (sometimes over two years) reduce', 'source_id': ''}, {'content': 'whole milk. In addition, the aging methods of traditional cheeses (sometimes over two years) reduce their lactose content to practically nothing. Commercial cheeses, however, are often manufactured by processes that do not have the same lactose-reducing properties. Ageing of some cheeses is governed by regulations; in other cases there is no quantitative indication of degree of ageing and concomitant lactose reduction, and lactose content is not usually indicated on labels.\"', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"List of goat cheeses\",\\n    \"text\": \"Goat cheese is produced using goat milk, the milk of domestic goats. Goat milk is commonly used to make cultured dairy products, including cheese. Myriad goat milk cheeses are produced around the world.\"\\n  },\\n  {\\n    \"title\": \"Cheesemaking\",\\n    \"text\": \"Although the common perception of cheese today is made from cow\\'s milk, goat\\'s milk was actually the preferred base of ancient cheesemakers, due to the fact that goats are smaller animals than cows. This meant that goats required less food and were easier to transport and herd. Moreover, goats can breed any time of the year as opposed to sheep, who also produce milk, but mating season only came around during fall and winter.\"\\n  },\\n  {\\n    \"title\": \"Goat cheese\",', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"Goat cheese\",\\n    \"text\": \"Cow\\'s milk and goat\\'s milk have similar overall fat contents. However, the higher proportion of medium-chain fatty acids such as caproic and caprylic in goat\\'s milk contributes to the characteristic tart flavor of goat\\'s milk cheese. (These fatty acids take their name from the Latin for \\\\\"goat\\\\\": \\\\\"capra\\\\\".) It also has a lower lactose content than cow\\'s milk.\"\\n  },\\n  {\\n    \"title\": \"Cheddar cheese\",\\n    \"text\": \"During the manufacture of cheddar cheese, the curds and whey are separated using rennet, an enzyme complex normally produced from the stomachs of newborn calves (in vegetarian or kosher cheeses, bacterial, yeast or mould-derived chymosin is used).\"\\n  },\\n  {\\n    \"title\": \"Dairy cattle\",', 'source_id': ''}, {'content': '},\\n  {\\n    \"title\": \"Dairy cattle\",\\n    \"text\": \"Whey protein makes up about 20% of milk’s protein composition and is separated from the casein (80% of milk’s protein make up) during the process of curdling cheese. This protein is commonly used in protein bars, beverages and concentrated powder, due to its high quality amino acid profile. It contains levels of both essential amino acids as well as branched that are above those of soy, meat, and wheat. \\\\\"Diafiltered\\\\\" milk is a process of ultrafiltration of the fluid milk to separate lactose and water from the casein and whey proteins. This process allows for more efficiency in cheese making and gives the potential to produce low-carb dairy products.\"\\n  },\\n  {\\n    \"title\": \"Casein\",', 'source_id': ''}]}\n"
     ]
    }
   ],
   "source": [
    "data = entities_out()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:00.654050100Z",
     "start_time": "2025-04-09T12:56:00.642494500Z"
    }
   },
   "id": "8485315466bd9b1a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Knowledge Graph Processing"
   ],
   "id": "41f57c6588db7408"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:09.891934300Z",
     "start_time": "2025-04-09T12:56:09.884832800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_knowledge_graph(json_data: Dict) -> Tuple[List[str], List[Tuple[int, int, dict]]]:\n",
    "    \"\"\"\n",
    "    Load knowledge graph data from JSON and prepare it for igraph conversion.\n",
    "\n",
    "    Args:\n",
    "        json_data: Dictionary containing entities and relationships\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - List of unique entity names\n",
    "        - List of edges with attributes\n",
    "    \"\"\"\n",
    "    # Extract entities and create a mapping of names to indices\n",
    "    entities = [entity['entity_name'].strip() for entity in json_data['entities']]\n",
    "    entity_to_idx = {name: idx for idx, name in enumerate(entities)}\n",
    "\n",
    "    # Process relationships into edge list with attributes\n",
    "    edges = []\n",
    "    for rel in json_data['relationships']:\n",
    "        src = rel['src_id'].strip()\n",
    "        tgt = rel['tgt_id'].strip()\n",
    "\n",
    "        # Only add edge if both nodes exist\n",
    "        if src in entity_to_idx and tgt in entity_to_idx:\n",
    "            edge_attrs = {\n",
    "                'description': rel['description'],\n",
    "                'weight': float(rel['weight']) if rel['weight'] else 1.0\n",
    "            }\n",
    "            edges.append((entity_to_idx[src], entity_to_idx[tgt], edge_attrs))\n",
    "\n",
    "    return entities, edges\n",
    "\n",
    "\n",
    "def create_igraph(vertices: List[str], edges: List[Tuple[int, int, dict]]) -> ig.Graph:\n",
    "    \"\"\"\n",
    "    Create an igraph Graph object from vertices and edges.\n",
    "\n",
    "    Args:\n",
    "        vertices: List of vertex names\n",
    "        edges: List of tuples (source_idx, target_idx, attributes)\n",
    "\n",
    "    Returns:\n",
    "        igraph.Graph object\n",
    "    \"\"\"\n",
    "    # Create directed graph\n",
    "    g = ig.Graph(directed=True)\n",
    "\n",
    "    # Add vertices\n",
    "    g.add_vertices(len(vertices))\n",
    "    g.vs['name'] = vertices\n",
    "\n",
    "    # Add edges with attributes\n",
    "    if edges:  # Check if there are any edges\n",
    "        edge_tuples = [(e[0], e[1]) for e in edges]\n",
    "        g.add_edges(edge_tuples)\n",
    "\n",
    "        # Add edge attributes\n",
    "        for idx, (_, _, attrs) in enumerate(edges):\n",
    "            for key, value in attrs.items():\n",
    "                if g.es.attribute_names().count(key) == 0:\n",
    "                    g.es[key] = [None] * len(g.es)\n",
    "                g.es[idx][key] = value\n",
    "\n",
    "    return g\n",
    "\n",
    "\n",
    "def personalized_pagerank_search(g: ig.Graph, query_vertices: List[str], damping: float = 0.85) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Perform personalized PageRank search on the graph.\n",
    "\n",
    "    Args:\n",
    "        g: igraph Graph object\n",
    "        query_vertices: List of vertex names to use as personalization vector\n",
    "        damping: Damping factor for PageRank (default: 0.85)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping vertex names to their PageRank scores\n",
    "    \"\"\"\n",
    "    # Create personalization vector by finding vertex indices\n",
    "    reset_vertices = []\n",
    "    for vertex in query_vertices:\n",
    "        try:\n",
    "            vertex_idx = g.vs.find(name=vertex).index\n",
    "            reset_vertices.append(vertex_idx)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # If no valid vertices found, use uniform distribution\n",
    "    if not reset_vertices:\n",
    "        return {v['name']: 1.0 / len(g.vs) for v in g.vs}\n",
    "\n",
    "    # Calculate personalized PageRank\n",
    "    weights = g.es.get_attribute_values('weight') if 'weight' in g.es.attributes() else None\n",
    "\n",
    "    pagerank_scores = g.personalized_pagerank(\n",
    "        weights=weights,\n",
    "        damping=damping,\n",
    "        reset_vertices=reset_vertices\n",
    "    )\n",
    "\n",
    "    # Create results dictionary\n",
    "    results = {v['name']: score for v, score in zip(g.vs, pagerank_scores)}\n",
    "    return dict(sorted(results.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "\n",
    "def process_knowledge_graph(json_data: Dict, query_entities: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Process knowledge graph and perform personalized PageRank search.\n",
    "\n",
    "    Args:\n",
    "        json_data: Knowledge graph data in JSON format\n",
    "        query_entities: List of entity names to search for\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of entity names and their PageRank scores\n",
    "    \"\"\"\n",
    "    # Convert JSON to igraph structure\n",
    "    vertices, edges = load_knowledge_graph(json_data)\n",
    "    graph = create_igraph(vertices, edges)\n",
    "\n",
    "    # Perform personalized PageRank search\n",
    "    results = personalized_pagerank_search(graph, query_entities)\n",
    "\n",
    "    return results"
   ],
   "id": "a9e485ae7951c671",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Improve Knowledge Graph Processing with similarity search"
   ],
   "id": "184c4a9c80e28858"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:11.060338900Z",
     "start_time": "2025-04-09T12:56:11.056169800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_knowledge_graph_with_embeddings(json_data: Dict) -> Tuple[List[str], List[Tuple[int, int, dict]], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load knowledge graph data with entity embeddings for similarity calculations.\n",
    "    \"\"\"\n",
    "    entities, edges = load_knowledge_graph(json_data)\n",
    "\n",
    "    # Generate embeddings for entities\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(entities)\n",
    "\n",
    "    return entities, edges, embeddings\n",
    "\n",
    "\n",
    "def similarity_weighted_pagerank(g: ig.Graph,\n",
    "                                 query_vertices: List[str],\n",
    "                                 embeddings: np.ndarray,\n",
    "                                 damping: float = 0.85,\n",
    "                                 similarity_weight: float = 0.5) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Combine PersonalizedPageRank with cosine similarity for ranking.\n",
    "    \"\"\"\n",
    "    # Get embeddings for query vertices\n",
    "    query_indices = []\n",
    "    for vertex in query_vertices:\n",
    "        try:\n",
    "            idx = g.vs.find(name=vertex).index\n",
    "            query_indices.append(idx)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not query_indices:\n",
    "        return {v['name']: 1.0 / len(g.vs) for v in g.vs}\n",
    "\n",
    "    # Calculate cosine similarities\n",
    "    query_embedding = np.mean(embeddings[query_indices], axis=0).reshape(1, -1)\n",
    "    similarities = cosine_similarity(embeddings, query_embedding).flatten()\n",
    "\n",
    "    # Calculate PageRank scores\n",
    "    weights = g.es.get_attribute_values('weight') if 'weight' in g.es.attributes() else None\n",
    "    pagerank_scores = g.personalized_pagerank(\n",
    "        weights=weights,\n",
    "        damping=damping,\n",
    "        reset_vertices=query_indices\n",
    "    )\n",
    "\n",
    "    # Combine scores\n",
    "    combined_scores = {}\n",
    "    for v, pr_score, sim_score in zip(g.vs, pagerank_scores, similarities):\n",
    "        combined_scores[v['name']] = (1 - similarity_weight) * pr_score + similarity_weight * sim_score\n",
    "\n",
    "    return dict(sorted(combined_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "\n",
    "def process_knowledge_graph_with_similarity(json_data: Dict,\n",
    "                                            query_entities: List[str],\n",
    "                                            similarity_weight: float = 0.5) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Process knowledge graph with combined PageRank and similarity scoring.\n",
    "    \"\"\"\n",
    "    vertices, edges, embeddings = load_knowledge_graph_with_embeddings(json_data)\n",
    "    graph = create_igraph(vertices, edges)\n",
    "    results = similarity_weighted_pagerank(\n",
    "        graph,\n",
    "        query_entities,\n",
    "        embeddings,\n",
    "        similarity_weight=similarity_weight\n",
    "    )\n",
    "    return results"
   ],
   "id": "6d69b796ac6b86d8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Improve Knowladge graph search with chain-of-thought"
   ],
   "id": "f955dbafe00e4bfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:12.116106Z",
     "start_time": "2025-04-09T12:56:12.106970500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ChainOfThoughtGraphSearch:\n",
    "    def __init__(self, json_data: Dict, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.vertices, self.edges, self.embeddings = load_knowledge_graph_with_embeddings(json_data)\n",
    "        self.graph = create_igraph(self.vertices, self.edges)\n",
    "        self.reasoning_history: List[Dict] = []\n",
    "\n",
    "    def iterative_search(self, query: str, max_steps: int = 3) -> Dict[str, float]:\n",
    "        current_entities = set(self._initial_entity_extraction(query))\n",
    "        all_relevant_entities: Set[str] = set()\n",
    "\n",
    "        for step in range(max_steps):\n",
    "            # Get current results\n",
    "            step_results = similarity_weighted_pagerank(\n",
    "                self.graph,\n",
    "                list(current_entities),\n",
    "                self.embeddings\n",
    "            )\n",
    "\n",
    "            # Update reasoning history\n",
    "            self.reasoning_history.append({\n",
    "                'step': step,\n",
    "                'query_entities': current_entities,\n",
    "                'top_results': dict(list(step_results.items())[:5])\n",
    "            })\n",
    "\n",
    "            # Expand search with new entities\n",
    "            new_entities = self._extract_related_entities(step_results, threshold=0.3)\n",
    "            all_relevant_entities.update(current_entities)\n",
    "            current_entities = new_entities - all_relevant_entities\n",
    "\n",
    "            if not current_entities:\n",
    "                break\n",
    "\n",
    "        return self._aggregate_results()\n",
    "\n",
    "    def _initial_entity_extraction(self, query: str) -> List[str]:\n",
    "        query_embedding = self.model.encode([query])[0]\n",
    "        similarities = cosine_similarity([query_embedding], self.embeddings)[0]\n",
    "        return [self.vertices[i] for i in np.argsort(similarities)[-3:]]\n",
    "\n",
    "    def _extract_related_entities(self, results: Dict[str, float], threshold: float) -> Set[str]:\n",
    "        return {entity for entity, score in results.items() if score > threshold}\n",
    "\n",
    "    def _aggregate_results(self) -> Dict[str, float]:\n",
    "        all_scores = {}\n",
    "        decay_factor = 0.8\n",
    "\n",
    "        for step, history in enumerate(self.reasoning_history):\n",
    "            step_weight = decay_factor ** step\n",
    "            for entity, score in history['top_results'].items():\n",
    "                all_scores[entity] = all_scores.get(entity, 0) + score * step_weight\n",
    "\n",
    "        return dict(sorted(all_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    def get_reasoning_chain(self) -> List[Dict]:\n",
    "        return self.reasoning_history"
   ],
   "id": "4e10c4385daa1789",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "id": "3050c7249e22a966"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:35:11.895078100Z",
     "start_time": "2025-04-09T05:35:11.878307900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_plotly_graph_visualization(\n",
    "        g: ig.Graph,\n",
    "        title: str,\n",
    "        pagerank_scores: Optional[Dict[str, float]] = None,\n",
    "        highlight_vertices: Optional[List[str]] = None,\n",
    "        edge_threshold: float = 0.0,\n",
    "        reasoning_step: Optional[int] = None,\n",
    "        embeddings: Optional[np.ndarray] = None\n",
    ") -> go.Figure:\n",
    "    \"\"\"\n",
    "    Create an interactive plotly visualization of the graph with embedding-based layout.\n",
    "\n",
    "    Args:\n",
    "        g: igraph Graph object\n",
    "        title: Title for the visualization\n",
    "        pagerank_scores: Optional dictionary of vertex names to PageRank scores\n",
    "        highlight_vertices: Optional list of vertex names to highlight\n",
    "        edge_threshold: Minimum PageRank score for vertices to include\n",
    "        reasoning_step: Optional step number in the reasoning chain\n",
    "        embeddings: Optional numpy array of entity embeddings for layout\n",
    "\n",
    "    Returns:\n",
    "        plotly Figure object\n",
    "    \"\"\"\n",
    "    # Use UMAP or PCA layout if embeddings are provided, otherwise use Kamada-Kawai\n",
    "    if embeddings is not None:\n",
    "        from umap import UMAP\n",
    "        layout = UMAP(n_components=2, random_state=42).fit_transform(embeddings)\n",
    "    else:\n",
    "        layout = g.layout_kamada_kawai()\n",
    "\n",
    "    # Calculate color scheme based on scores\n",
    "    if pagerank_scores:\n",
    "        scores = np.array([pagerank_scores.get(v['name'], 0) for v in g.vs])\n",
    "        normalized_scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "        colorscale = px.colors.sequential.Viridis\n",
    "        vertex_colors = [px.colors.sample_colorscale(colorscale, score)[0]\n",
    "                         for score in normalized_scores]\n",
    "    else:\n",
    "        vertex_colors = ['lightblue'] * len(g.vs)\n",
    "\n",
    "    # Adjust vertex sizes based on scores and highlighting\n",
    "    vertex_sizes = [30] * len(g.vs)\n",
    "    if pagerank_scores:\n",
    "        max_score = max(pagerank_scores.values())\n",
    "        for i, vertex in enumerate(g.vs):\n",
    "            score = pagerank_scores.get(vertex['name'], 0)\n",
    "            vertex_sizes[i] = 20 + (score / max_score) * 50\n",
    "\n",
    "            if highlight_vertices and vertex['name'] in highlight_vertices:\n",
    "                vertex_colors[i] = 'red'\n",
    "                vertex_sizes[i] *= 1.5\n",
    "\n",
    "    # Create edge traces with improved styling\n",
    "    edge_traces = []\n",
    "    for edge in g.es:\n",
    "        source = g.vs[edge.source]\n",
    "        target = g.vs[edge.target]\n",
    "\n",
    "        if pagerank_scores:\n",
    "            source_score = pagerank_scores.get(source['name'], 0)\n",
    "            target_score = pagerank_scores.get(target['name'], 0)\n",
    "            if source_score < edge_threshold or target_score < edge_threshold:\n",
    "                continue\n",
    "\n",
    "        x0, y0 = layout[edge.source]\n",
    "        x1, y1 = layout[edge.target]\n",
    "\n",
    "        # Calculate edge width based on weight\n",
    "        weight = edge['weight'] if 'weight' in g.es.attributes() else 1.0\n",
    "        edge_width = 0.5 + weight * 2\n",
    "\n",
    "        # Correctly access edge description attribute\n",
    "        description = edge['description'] if 'description' in g.es.attributes() else ''\n",
    "\n",
    "        edge_trace = go.Scatter(\n",
    "            x=[x0, x1, None],\n",
    "            y=[y0, y1, None],\n",
    "            mode='lines',\n",
    "            line=dict(width=edge_width, color='#888'),\n",
    "            hoverinfo='text',\n",
    "            text=description\n",
    "        )\n",
    "        edge_traces.append(edge_trace)\n",
    "\n",
    "    # Create figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add edges\n",
    "    for trace in edge_traces:\n",
    "        fig.add_trace(trace)\n",
    "\n",
    "    # Add nodes with improved styling\n",
    "    node_trace = go.Scatter(\n",
    "        x=[layout[i][0] for i in range(len(g.vs))],\n",
    "        y=[layout[i][1] for i in range(len(g.vs))],\n",
    "        mode='markers+text',\n",
    "        marker=dict(\n",
    "            size=vertex_sizes,\n",
    "            color=vertex_colors,\n",
    "            line=dict(width=2, color='black'),\n",
    "            symbol='circle'\n",
    "        ),\n",
    "        text=[f\"{v['name']}<br>Score: {pagerank_scores.get(v['name'], 0):.4f}\"\n",
    "              if pagerank_scores else v['name'] for v in g.vs],\n",
    "        textposition=\"top center\",\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "    fig.add_trace(node_trace)\n",
    "\n",
    "    # Update layout with reasoning step information\n",
    "    title_text = f\"{title}<br>Step {reasoning_step}\" if reasoning_step is not None else title\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=title_text,\n",
    "            x=0.5,\n",
    "            y=0.95\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=20, l=5, r=5, t=60),\n",
    "        plot_bgcolor='white',\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_reasoning_chain_visualization(\n",
    "        search_instance: 'ChainOfThoughtGraphSearch',\n",
    "        score_threshold: float = 0.01\n",
    ") -> List[go.Figure]:\n",
    "    \"\"\"\n",
    "    Create visualizations for each step in the reasoning chain.\n",
    "\n",
    "    Args:\n",
    "        search_instance: ChainOfThoughtGraphSearch instance\n",
    "        score_threshold: Threshold for including vertices\n",
    "\n",
    "    Returns:\n",
    "        List of plotly figures, one for each reasoning step\n",
    "    \"\"\"\n",
    "    figures = []\n",
    "\n",
    "    for step, history in enumerate(search_instance.reasoning_history):\n",
    "        step_fig = create_plotly_graph_visualization(\n",
    "            search_instance.graph,\n",
    "            f\"Knowledge Graph Exploration - Step {step + 1}\",\n",
    "            history['top_results'],\n",
    "            list(history['query_entities']),\n",
    "            score_threshold,\n",
    "            step + 1,\n",
    "            search_instance.embeddings\n",
    "        )\n",
    "        figures.append(step_fig)\n",
    "\n",
    "    return figures\n",
    "\n",
    "\n",
    "def display_graph_visualizations(\n",
    "        search_instance: 'ChainOfThoughtGraphSearch',\n",
    "        score_threshold: float = 0.01\n",
    ") -> Tuple[go.Figure, List[go.Figure]]:\n",
    "    \"\"\"\n",
    "    Process knowledge graph and create full visualization plus reasoning chain.\n",
    "\n",
    "    Args:\n",
    "        search_instance: ChainOfThoughtGraphSearch instance\n",
    "        score_threshold: Threshold for including vertices\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (final_graph_figure, list_of_reasoning_step_figures)\n",
    "    \"\"\"\n",
    "    # Create final aggregate visualization\n",
    "    final_results = search_instance._aggregate_results()\n",
    "    final_graph = create_plotly_graph_visualization(\n",
    "        search_instance.graph,\n",
    "        \"Final Knowledge Graph Results\",\n",
    "        final_results,\n",
    "        list(search_instance.reasoning_history[-1]['query_entities']),\n",
    "        score_threshold,\n",
    "        embeddings=search_instance.embeddings\n",
    "    )\n",
    "\n",
    "    # Create reasoning chain visualizations\n",
    "    reasoning_steps = create_reasoning_chain_visualization(\n",
    "        search_instance,\n",
    "        score_threshold\n",
    "    )\n",
    "\n",
    "    return final_graph, reasoning_steps"
   ],
   "id": "c26fc3bdc22a191c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TavilySearchResults' object has no attribute '_aggregate_results'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[58]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Create visualizations\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m final_graph, reasoning_steps = \u001B[43mdisplay_graph_visualizations\u001B[49m\u001B[43m(\u001B[49m\u001B[43msearch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Display figures (if using in a notebook)\u001B[39;00m\n\u001B[32m      5\u001B[39m final_graph.show()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[57]\u001B[39m\u001B[32m, line 176\u001B[39m, in \u001B[36mdisplay_graph_visualizations\u001B[39m\u001B[34m(search_instance, score_threshold)\u001B[39m\n\u001B[32m    165\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    166\u001B[39m \u001B[33;03mProcess knowledge graph and create full visualization plus reasoning chain.\u001B[39;00m\n\u001B[32m    167\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    173\u001B[39m \u001B[33;03m    Tuple of (final_graph_figure, list_of_reasoning_step_figures)\u001B[39;00m\n\u001B[32m    174\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    175\u001B[39m \u001B[38;5;66;03m# Create final aggregate visualization\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m final_results = \u001B[43msearch_instance\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_aggregate_results\u001B[49m()\n\u001B[32m    177\u001B[39m final_graph = create_plotly_graph_visualization(\n\u001B[32m    178\u001B[39m     search_instance.graph,\n\u001B[32m    179\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mFinal Knowledge Graph Results\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    183\u001B[39m     embeddings=search_instance.embeddings\n\u001B[32m    184\u001B[39m )\n\u001B[32m    186\u001B[39m \u001B[38;5;66;03m# Create reasoning chain visualizations\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Asus\\Desktop\\Final Year\\Research\\CodeSpace\\Research\\venv\\Lib\\site-packages\\pydantic\\main.py:994\u001B[39m, in \u001B[36mBaseModel.__getattr__\u001B[39m\u001B[34m(self, item)\u001B[39m\n\u001B[32m    991\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[32m    992\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    993\u001B[39m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m994\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: 'TavilySearchResults' object has no attribute '_aggregate_results'"
     ]
    }
   ],
   "source": [
    "# Create visualizations\n",
    "final_graph, reasoning_steps = display_graph_visualizations(search)\n",
    "\n",
    "# Display figures (if using in a notebook)\n",
    "final_graph.show()\n",
    "for step_fig in reasoning_steps:\n",
    "    step_fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T16:39:39.002718400Z",
     "start_time": "2025-04-06T16:39:37.725598800Z"
    }
   },
   "id": "b86e99aff8094d4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chunk retriever"
   ],
   "id": "a27fbd225c841833"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:17.673843600Z",
     "start_time": "2025-04-09T12:56:17.642011600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class KnowledgeGraphChunkRetriever:\n",
    "    def __init__(self, json_data: Dict):\n",
    "        \"\"\"\n",
    "        Initialize the retriever with knowledge graph data.\n",
    "\n",
    "        Args:\n",
    "            json_data: Dictionary containing entities, relationships, and chunks\n",
    "        \"\"\"\n",
    "        self.entities = [entity['entity_name'].strip() for entity in json_data['entities']]\n",
    "        self.chunks = json_data['chunks']\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "        # Create chunk embeddings\n",
    "        self.chunk_embeddings = self.model.encode([chunk['content'] for chunk in self.chunks])\n",
    "\n",
    "        # Create entity to chunk mapping\n",
    "        self.entity_chunks = self._create_entity_chunk_mapping()\n",
    "\n",
    "    def _create_entity_chunk_mapping(self) -> Dict[str, Set[int]]:\n",
    "        \"\"\"Create a mapping of entities to chunk indices where they appear.\"\"\"\n",
    "        entity_chunks = {entity: set() for entity in self.entities}\n",
    "\n",
    "        for chunk_idx, chunk in enumerate(self.chunks):\n",
    "            chunk_content = chunk['content'].lower()\n",
    "            for entity in self.entities:\n",
    "                if entity.lower() in chunk_content:\n",
    "                    entity_chunks[entity].add(chunk_idx)\n",
    "\n",
    "        return entity_chunks\n",
    "\n",
    "    def get_relevant_chunks(self, ranked_entities: Dict[str, float],\n",
    "                            max_chunks: int = 5,\n",
    "                            similarity_threshold: float = 0.3) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant chunks based on ranked entities.\n",
    "\n",
    "        Args:\n",
    "            ranked_entities: Dictionary of entity names and their importance scores\n",
    "            max_chunks: Maximum number of chunks to return\n",
    "            similarity_threshold: Minimum similarity score threshold\n",
    "\n",
    "        Returns:\n",
    "            List of relevant chunks with their scores\n",
    "        \"\"\"\n",
    "        # Collect chunk indices from top entities\n",
    "        relevant_chunk_indices = set()\n",
    "        for entity in ranked_entities:\n",
    "            relevant_chunk_indices.update(self.entity_chunks.get(entity, set()))\n",
    "\n",
    "        if not relevant_chunk_indices:\n",
    "            return []\n",
    "\n",
    "        # Calculate chunk scores\n",
    "        chunk_scores = []\n",
    "        for chunk_idx in relevant_chunk_indices:\n",
    "            score = self._calculate_chunk_score(\n",
    "                chunk_idx,\n",
    "                ranked_entities,\n",
    "                self.chunk_embeddings[chunk_idx]\n",
    "            )\n",
    "            if score >= similarity_threshold:\n",
    "                chunk_scores.append({\n",
    "                    'chunk': self.chunks[chunk_idx],\n",
    "                    'score': score,\n",
    "                    'relevant_entities': [\n",
    "                        entity for entity in ranked_entities\n",
    "                        if chunk_idx in self.entity_chunks[entity]\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "        # Sort and return top chunks\n",
    "        chunk_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "        return chunk_scores[:max_chunks]\n",
    "\n",
    "    def _calculate_chunk_score(self,\n",
    "                               chunk_idx: int,\n",
    "                               ranked_entities: Dict[str, float],\n",
    "                               chunk_embedding: np.ndarray) -> float:\n",
    "        \"\"\"Calculate relevance score for a chunk based on entities and content.\"\"\"\n",
    "        # Entity presence score\n",
    "        entity_score = sum(\n",
    "            ranked_entities[entity]\n",
    "            for entity in ranked_entities\n",
    "            if chunk_idx in self.entity_chunks[entity]\n",
    "        )\n",
    "\n",
    "        # Normalize entity score\n",
    "        if entity_score > 0:\n",
    "            entity_score = entity_score / max(ranked_entities.values())\n",
    "\n",
    "        return entity_score\n",
    "\n",
    "\n",
    "def process_query_with_chunks(json_data: Dict,\n",
    "                              graph_search_results: Dict[str, float]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process a query and return relevant chunks based on graph search results.\n",
    "\n",
    "    Args:\n",
    "        json_data: Knowledge graph data\n",
    "        query_entities: List of query entity names\n",
    "        graph_search_results: Results from graph search algorithm\n",
    "\n",
    "    Returns:\n",
    "        List of relevant chunks with scores and metadata\n",
    "    \"\"\"\n",
    "    retriever = KnowledgeGraphChunkRetriever(json_data)\n",
    "    return retriever.get_relevant_chunks(graph_search_results)"
   ],
   "id": "728a1980ca8de787",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Pydantic class definition\n",
    "class FeedbackAgent(BaseModel):\n",
    "    chunk_number:int=Field(description=\"chunk number of the provided dictionary\")\n",
    "    relevancy:bool=Field(description=\"whether the chunk is relevant to the question or not\")\n",
    "    feedback:list[str]=Field(description=\"feedbacks to the retrieved content.\")\n",
    "\n",
    "class Feedbacks(BaseModel):\n",
    "    feedback:list[FeedbackAgent]=Field(description=\"List of feedbacks\")\n",
    "\n",
    "class QueryReformation(BaseModel):\n",
    "    user_query:str=Field(description=\"original user question\")\n",
    "    new_query:str=Field(description=\"reformated question\")\n",
    "\n",
    "def search_kg(user_query, data):\n",
    "    \"\"\"\n",
    "    search knowledge graph for extract relevent chunks\n",
    "\n",
    "    :param user_query: user question\n",
    "    :param data: json data of knowledge graph\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    search = ChainOfThoughtGraphSearch(data)\n",
    "    graph_results = search.iterative_search(user_query)\n",
    "\n",
    "    # Then retrieve relevant chunks\n",
    "    chunk_results = process_query_with_chunks(data, graph_results)\n",
    "    # print(chunk_results)\n",
    "    return chunk_results\n",
    "\n",
    "def get_feedbacks(chunk_results, user_query):\n",
    "    \"\"\"This function is used to get the feedbacks to the retrived chunks to check whether the retrived chunks are relevant to the query or not\"\"\"\n",
    "    #define empty variable for relevancy score\n",
    "    rel_score = 0\n",
    "    negative_feedback = [] # define empty list for collect feedbacks\n",
    "    result = []\n",
    "\n",
    "    #looping through the content\n",
    "    for idx, item in enumerate(chunk_results, start=1):\n",
    "        chunk_dict = {\n",
    "            'chunk': idx,\n",
    "            'content': item['chunk']['content']\n",
    "        }\n",
    "        result.append(chunk_dict)\n",
    "\n",
    "    # define feedbacks structured output\n",
    "    feedback_structured_output_model = llm.with_structured_output(schema=Feedbacks)\n",
    "\n",
    "    feedback_list_from_llm = feedback_structured_output_model.invoke(\n",
    "        [{\"role\":\"system\",\n",
    "          \"content\":\"You are a precise content relevance analyzer. Evaluate the relevance between the provided query and retrieved content chunks based on these criteria:\\n\\n1. Semantic relationship: Does the content directly address the query's main topic?\\n2. Information value: Does the content provide useful information that helps answer the query?\\n3. Context alignment: Is the content in the appropriate context of the query?\\n\\nOutput format:\\n- If relevant: Return 'True'\\n- If not relevant: Return 'False' followed by a JSON array of specific reasons why the content doesn't match the query's requirements\\n\\nExample reasons format:\\n[\\\"Content discusses different topic than query\\\", \\\"Information is too general\\\", \\\"Context is inappropriate for the question\\\"]\\n\\nBe concise and decisive in your assessment.\"},\n",
    "         {\"role\":\"user\",\n",
    "          \"content\": f\"Query: {user_query} \\n Retrieved Content:{result}\"}\n",
    "          ])\n",
    "\n",
    "    # check whether feedbacks are negative or not\n",
    "    for element in feedback_list_from_llm.feedback:\n",
    "        # print(element)\n",
    "        if not element.relevancy:\n",
    "            rel_score += 1\n",
    "            negative_feedback.append(element)\n",
    "    \n",
    "    return rel_score, feedback_list_from_llm\n",
    "\n",
    "    \n",
    "def entity_set_formation():\n",
    "    \"\"\"This function is used to get all the entities from data and create an entities set with no duplicates.\"\"\"\n",
    "    entities_set = set()\n",
    "    entities_list = []\n",
    "    \n",
    "    for entities in data['entities']:\n",
    "        entities_list.append(entities['entity_name'])\n",
    "\n",
    "    entities_set.update(entities_list)\n",
    "\n",
    "    return entities_set\n",
    "\n",
    "\n",
    "def question_reform(feedback_list_from_llm, user_query):\n",
    "    \"\"\"Reform the user query by using feedbacks received from the LLM and entities in the document corpus\"\"\"\n",
    "    \n",
    "    entity_set = entity_set_formation()\n",
    "    feedback_list=[] # empty list for create one collection feedback string\n",
    "\n",
    "    for element in feedback_list_from_llm.feedback:\n",
    "    # print(element)\n",
    "        if element.feedback:\n",
    "            feedback_list.append(\", \".join(element.feedback))\n",
    "\n",
    "    feedbacks = \"\\n\".join(feedback_list)\n",
    "\n",
    "    # define new formatted query structured\n",
    "    query_structured_output_model = model.with_structured_output(schema=QueryReformation)\n",
    "    llm_remormated_query = query_structured_output_model.invoke(\n",
    "        [{\"role\":\"system\",\n",
    "          \"content\":\"\"\"You are a strict query optimization expert. Your mission is to enhance search queries while adhering to these mandatory requirements:\n",
    "\n",
    "1. PRIMARY CONSTRAINTS:\n",
    "- Generate queries using ONLY terms from the provided entity keyword set\n",
    "- NEVER introduce concepts or terms not present in the entity keywords\n",
    "- ANY deviation from the provided keywords will result in query rejection\n",
    "\n",
    "2. ENHANCEMENT PROCESS:\n",
    "- Start with the original query's core intent\n",
    "- Match query concepts to available entity keywords\n",
    "- Incorporate relevant feedback to avoid previous issues\n",
    "- If a concept cannot be expressed using entity keywords, drop it\n",
    "- If the query cannot be reformulated using available keywords, respond with 'QUERY NOT POSSIBLE'\n",
    "\n",
    "3. FORMATTING RULES:\n",
    "- Output format: single enhanced query string\n",
    "- Maximum length: 2 sentences\n",
    "- Must maintain grammatical correctness\n",
    "- Include specific entity keywords verbatim\n",
    "\n",
    "4. QUALITY CHECKS:\n",
    "- Verify every term against entity keyword set\n",
    "- Ensure semantic relationship to original query\n",
    "- Confirm alignment with knowledge base feedback\n",
    "- Validate that no external concepts are introduced\n",
    "\n",
    "CRITICAL: If you cannot construct a meaningful query using ONLY the provided ENTITY KEYWORDS, output 'QUERY NOT POSSIBLE' instead of attempting to generate an invalid query beyond the entity keywords.\n",
    "    \"\"\"     \n",
    "        },\n",
    "         {\"role\":\"user\",\n",
    "          \"content\": f\"Original Query:{user_query}\\nRetrieval Feedback:{feedbacks}\\nAllowed Keywords:{entity_set}\"}\n",
    "          ])\n",
    "    print(llm_remormated_query)\n",
    "    return llm_remormated_query\n",
    "\n",
    "\n",
    "# First perform graph search\n",
    "def chain_of_thought_graphsearch(user_query, data):\n",
    "\n",
    "    chunk_results = search_kg(user_query, data)\n",
    "    rel_score, feedback_list_from_llm = get_feedbacks(chunk_results, user_query)\n",
    "            \n",
    "    if rel_score > 3:\n",
    "        llm_remormated_query = question_reform(feedback_list_from_llm,user_query) # call query reformation function\n",
    "        # print(reformatted_question.new_query)\n",
    "        answer_chunks = search_kg(llm_remormated_query.new_query,data)\n",
    "        \n",
    "        # loop for only take the content from the answer chunk\n",
    "        chunks_content =[]\n",
    "        for contents in answer_chunks:\n",
    "            chunks_content.append(contents.get('chunk').get('content'))\n",
    "        \n",
    "        #TavilySearch function calling\n",
    "        search_result = tavily_search(llm_remormated_query.new_query)\n",
    "        answer = answer_ranking(chunks_content, search_result,llm_remormated_query.new_query)\n",
    "        \n",
    "        \n",
    "        #LLM call function for Final answer creation\n",
    "        final_answer = final_answer_creation(llm_remormated_query.new_query,answer)\n",
    "        \n",
    "        save_qa_to_json(user_query,final_answer)\n",
    "        print(f\"Q&A pair successfully saved\")\n",
    "        # print(final_answer)\n",
    "        \n",
    "    else:\n",
    "        search_result = tavily_search(user_query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:18.470407900Z",
     "start_time": "2025-04-09T12:56:18.451088500Z"
    }
   },
   "id": "f16d89b07c208b73"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# create TavilySearch instance\n",
    "search = TavilySearchResults(\n",
    "    max_results=5,\n",
    "    search_depth=\"advanced\",\n",
    "    include_answer=True,\n",
    "    include_raw_content=True,\n",
    "    include_images=True,\n",
    "    # include_domains=[...],\n",
    "    # exclude_domains=[...],\n",
    "    # name=\"...\",            # overwrite default tool name\n",
    "    # description=\"...\",     # overwrite default tool description\n",
    "    # args_schema=...,       # overwrite default args_schema: BaseModel\n",
    ")\n",
    "\n",
    "def tavily_search(new_query):\n",
    "    \n",
    "    search_results = search.invoke({\"query\":new_query})\n",
    "    content_list =[]\n",
    "    for search_result in search_results:\n",
    "        content_list.append(search_result['content'])\n",
    "        \n",
    "    return content_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:19.007731300Z",
     "start_time": "2025-04-09T12:56:18.984739300Z"
    }
   },
   "id": "dc15c3c073f90485"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "def answer_ranking(chunk_content, search_result, new_query):\n",
    "    \"\"\"Rank the answers based on the relevancy for the query.\"\"\"\n",
    "    chunk_content.extend(search_result)\n",
    "    tokenized_corpus = [doc.split(\" \") for doc in chunk_content]\n",
    "    bm25 = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    query=new_query.lower()\n",
    "    tokenized_query = query.split(\" \")\n",
    "    doc_scores = bm25.get_scores(tokenized_query)\n",
    "    result = bm25.get_top_n(tokenized_query, tokenized_corpus, n=len(chunk_content))\n",
    "    \n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:19.545333600Z",
     "start_time": "2025-04-09T12:56:19.531212Z"
    }
   },
   "id": "ef2eccfe689f53ba"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def final_answer_creation(new_query, answer):\n",
    "    final_answer = model.invoke(\n",
    "        [{\"role\":\"system\",\n",
    "          \"content\":\"\"\"You are a precise answer synthesizer. Follow these requirements to generate accurate responses:\n",
    "\n",
    "1. ERROR HANDLING:\n",
    "- If user_query or User question equals 'QUERY NOT POSSIBLE', return exactly: 'Cannot generate an answer to your question, please update your question'\n",
    "- If answer chunks don't contain relevant information, respond with 'INSUFFICIENT CONTEXT'\n",
    "\n",
    "2. SYNTHESIS RULES:\n",
    "- Use ONLY information present in the provided answer chunks\n",
    "- Maintain factual accuracy without adding external knowledge\n",
    "- Provide direct answers to the specific question asked\n",
    "\n",
    "3. RESPONSE FORMAT:\n",
    "- you should try to keep your answers short when possible otherwise concise answers maximum two sentence\n",
    "- Use clear, simple language\n",
    "- Maintain consistent tone throughout\n",
    "\n",
    "4. QUALITY STANDARDS:\n",
    "- Verify all information against provided chunks\n",
    "- Ensure logical flow of information\n",
    "- Avoid speculation or assumptions\n",
    "- Present information in order of relevance\n",
    "- If chunks contain conflicting information, acknowledge the conflict\n",
    "\n",
    "5. PROHIBITED ACTIONS:\n",
    "- No external knowledge incorporation\n",
    "- No speculation beyond provided chunks\n",
    "- No generalization without supporting evidence\n",
    "- No answering questions outside chunk scope\n",
    "- No combining unrelated information\"\"\"\n",
    "        },\n",
    "         {\"role\":\"user\",\n",
    "          \"content\": f\"User question:{new_query}\\nanswer chunks:{answer}\"}\n",
    "          ])\n",
    "    return final_answer.content   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:22.146173400Z",
     "start_time": "2025-04-09T12:56:22.144210100Z"
    }
   },
   "id": "37caa29c8f86f439"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def save_qa_to_json(query, answer, filename=\"qa_data.json\"):\n",
    "    \"\"\"\n",
    "    Creates a dictionary from a question and answer pair and saves it to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The question text\n",
    "        answer (str): The answer text\n",
    "        filename (str): Name of the output JSON file (default: 'qa_data.json')\n",
    "        \n",
    "    Returns:\n",
    "        dict: The created question-answer dictionary\n",
    "    \"\"\"\n",
    "    # Create the QA dictionary\n",
    "    qa_dict = {\n",
    "        \"question\": query,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "        # Check if the file already exists\n",
    "    if os.path.exists(filename):\n",
    "        # Read existing data\n",
    "        try:\n",
    "            with open(filename, 'r') as file:\n",
    "                existing_data = json.load(file)\n",
    "                \n",
    "            # If the existing data is a list, append to it\n",
    "            if isinstance(existing_data, list):\n",
    "                existing_data.append(qa_dict)\n",
    "                qa_data = existing_data\n",
    "            # If it's a dictionary, convert to a list with both items\n",
    "            else:\n",
    "                qa_data = [existing_data, qa_dict]\n",
    "        except json.JSONDecodeError:\n",
    "            # If the file exists but isn't valid JSON, start fresh\n",
    "            qa_data = [qa_dict]\n",
    "    else:\n",
    "        # If the file doesn't exist, create new data\n",
    "        qa_data = [qa_dict]\n",
    "    \n",
    "    # Save the data to the JSON file\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(qa_data, file, indent=4)\n",
    "    \n",
    "    print(f\"Q&A pair successfully saved to {filename}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:22.951525500Z",
     "start_time": "2025-04-09T12:56:22.936377500Z"
    }
   },
   "id": "b347f6e807ef1b64"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def load_questions(file_path):\n",
    "    \"\"\"\n",
    "    Load questions from a JSON file and return them as a list.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file containing questions\n",
    "        \n",
    "    Returns:\n",
    "        list: List of questions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            # Split by newlines to get individual questions\n",
    "            questions = [q for q in content.strip().split('\\n') if q]\n",
    "            return questions\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: File '{file_path}' is not valid JSON.\")\n",
    "        return []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T12:56:24.121104600Z",
     "start_time": "2025-04-09T12:56:24.104361900Z"
    }
   },
   "id": "27610f59d0c695f3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1: When did people first start making cheese?\n",
      "user_query='When did people first start making cheese?' new_query='history of traditional cheeses'\n",
      "Q&A pair successfully saved to qa_data.json\n",
      "Q&A pair successfully saved\n",
      "\n",
      "Question 2: Do all cheeses need to be refrigerated?\n",
      "user_query='Do all cheeses need to be refrigerated?' new_query='Do commercial cheeses and traditional cheeses require refrigeration?'\n",
      "Q&A pair successfully saved to qa_data.json\n",
      "Q&A pair successfully saved\n"
     ]
    }
   ],
   "source": [
    "questions = load_questions(\"inscit_query.json\")\n",
    "if questions:\n",
    "    for i, question in enumerate(questions[2:4]):  # Limit to 10 questions\n",
    "        print(f\"\\nQuestion {i+1}: {question}\")\n",
    "        chain_of_thought_graphsearch(user_query=question, data=data)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T13:00:20.258793Z",
     "start_time": "2025-04-09T12:56:26.613919100Z"
    }
   },
   "id": "777fbeb0a70fdb77"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_query='What are the effects of cheese on health?' new_query=\"What are the health effects of cheese made from cow's milk, goat's milk, or whole milk?\"\n",
      "Goat cheese is generally healthier than cow's milk cheese, offering benefits like easier digestion, lower calories, and less saturated fat. It also contains more medium-chain fatty acids and has a lower lactose content, making it suitable for those with lactose intolerance. Whole milk cheeses can be high in saturated fat, which may require moderation for individuals with cardiovascular concerns. Both types provide essential nutrients like calcium and protein, supporting bone and muscle health. \n",
      "\n",
      "Key differences:\n",
      "- Goat cheese has A-2 beta-casein (less allergenic) vs. cow cheese's A-1 beta-casein\n",
      "- Goat cheese may reduce inflammation and diabetes risk more effectively\n",
      "- Whole milk cheeses offer higher fat content (beneficial for nutrient absorption but may need restriction in certain diets)\n"
     ]
    }
   ],
   "source": [
    "chain_of_thought_graphsearch(user_query =\"What are the effects of cheese on health?\",data=data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-09T09:34:24.238094Z"
    }
   },
   "id": "481563481bd930f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "536ddb78d4c2e988"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
